"""
MEXC Data Collector - MEXCã‹ã‚‰ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’QuestDBã«è¨˜éŒ²
"""

import asyncio
import logging
import signal
import sys
import time
from datetime import datetime
from typing import Any, Dict

# ãƒ­ã‚°è¨­å®š
from loguru import logger as loguru_logger

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ­ã‚¬ãƒ¼
logger = loguru_logger

# è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from config import Config
from data_manager import DataManager
from mexc_client import MEXCClient, TickData
from questdb_client import QuestDBClient


class MEXCDataCollector:
    """MEXCãƒ‡ãƒ¼ã‚¿åé›†ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³"""

    def __init__(self, config_path: str = "config.yml"):
        """
        åˆæœŸåŒ–

        Args:
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        # è¨­å®šèª­ã¿è¾¼ã¿
        self.config = Config(config_path)

        # ãƒ­ã‚°è¨­å®š
        self._setup_logging()

        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self.mexc_client = None
        self.data_manager = None
        self.questdb_client = None

        # å®Ÿè¡Œåˆ¶å¾¡
        self.running = False
        self.shutdown_event = asyncio.Event()

        # çµ±è¨ˆ
        self.stats = {
            "start_time": datetime.now(),
            "ticks_processed": 0,
            "ticks_saved": 0,
            "batches_received": 0,
        }

        logger.info("ğŸ† MEXC Data CollectoråˆæœŸåŒ–å®Œäº†")

    def _setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""
        # æ—¢å­˜ã®ãƒ­ã‚°ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’å‰Šé™¤
        loguru_logger.remove()

        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
        loguru_logger.add(
            sys.stderr,
            level=self.config.log_level,
            format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | "
            "<level>{level: <8}</level> | "
            "<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - "
            "<level>{message}</level>",
        )

        # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
        loguru_logger.add(
            self.config.log_file,
            level=self.config.log_level,
            rotation=f"{self.config.get('logging.max_size_mb', 10)} MB",
            retention=self.config.get("logging.backup_count", 5),
            encoding="utf-8",
        )

        # æ¨™æº–loggingãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’loguru ã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ
        logging.basicConfig(handlers=[], level=logging.DEBUG)
        logging.getLogger().handlers.clear()

        class InterceptHandler(logging.Handler):
            def emit(self, record):
                try:
                    level = loguru_logger.level(record.levelname).name
                except ValueError:
                    level = record.levelno

                frame, depth = logging.currentframe(), 2
                while frame.f_code.co_filename == logging.__file__:
                    frame = frame.f_back
                    depth += 1

                loguru_logger.opt(depth=depth, exception=record.exc_info).log(
                    level, record.getMessage()
                )

        logging.getLogger().addHandler(InterceptHandler())

    async def initialize(self):
        """ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–"""
        logger.info("ğŸ”§ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–ä¸­...")

        try:
            # MEXCã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
            self.mexc_client = MEXCClient(self.config)
            logger.info("MEXCã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆå®Œäº†")

            # ãƒ‡ãƒ¼ã‚¿ç®¡ç†
            self.data_manager = DataManager(self.config)
            logger.info("ãƒ‡ãƒ¼ã‚¿ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ä½œæˆå®Œäº†")

            # QuestDB ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
            self.questdb_client = QuestDBClient(self.config)
            logger.info("QuestDBã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆå®Œäº†")

            # MEXC WebSocket æ¥ç¶š
            if not await self.mexc_client.start():
                raise Exception("MEXC WebSocketæ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ")

            # ãƒ†ã‚£ãƒƒã‚«ãƒ¼ãƒãƒƒãƒã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š
            self.mexc_client.set_batch_callback(self._on_ticker_batch_received)

            # å…¨éŠ˜æŸ„è³¼èª­
            if not await self.mexc_client.subscribe_all_tickers():
                raise Exception("Failed to subscribe to all tickers")

            logger.info("âœ… å…¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®åˆæœŸåŒ–æˆåŠŸ")

        except Exception as e:
            logger.error(f"âŒ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–å¤±æ•—: {e}")
            await self.shutdown()
            raise

    def _on_ticker_batch_received(self, tickers: list):
        """WebSocketå—ä¿¡ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
        try:
            self.stats["batches_received"] += 1
            current_time = datetime.now().strftime("%H:%M:%S.%f")[:-3]

            logger.info(
                f"ğŸ“¨ [{current_time}] Batch #{self.stats['batches_received']}: {len(tickers)} tickers received"
            )

            # ğŸš€ é«˜é€ŸåŒ–: éåŒæœŸã§ãƒ‡ãƒ¼ã‚¿å‡¦ç†ï¼ˆä¸¦åˆ—å‡¦ç†ï¼‰
            asyncio.create_task(self._process_ticker_batch_fast(tickers, self.stats["batches_received"]))

        except Exception as e:
            logger.error(f"Error in reception callback: {e}")

    async def _process_ticker_batch_fast(self, tickers: list, batch_id: int):
        """é«˜é€Ÿãƒãƒƒãƒå‡¦ç†ï¼ˆä¸¦åˆ—æœ€é©åŒ–ç‰ˆï¼‰"""
        try:
            start_time = time.time()
            
            # ğŸš€ å³åº§ã«çµ±è¨ˆæ›´æ–°ï¼ˆãƒ¬ã‚¹ãƒãƒ³ã‚¹å„ªå…ˆï¼‰
            self.stats["ticks_processed"] += len(tickers)
            
            # ğŸš€ QuestDBä¿å­˜ã‚’ä¸¦åˆ—å®Ÿè¡Œ
            save_task = asyncio.create_task(self._save_to_questdb_fast(tickers, start_time))
            
            # ğŸš€ data_manageræ›´æ–°ã‚’ä¸¦åˆ—å®Ÿè¡Œ
            data_task = asyncio.create_task(self._update_data_manager_fast(tickers))
            
            # ä¸¡æ–¹ã®å‡¦ç†ã‚’ä¸¦åˆ—å®Ÿè¡Œ
            saved_count, processed_count = await asyncio.gather(save_task, data_task)
            
            # çµ±è¨ˆæ›´æ–°
            self.stats["ticks_saved"] += saved_count
            
            duration = time.time() - start_time
            
            # ãƒ­ã‚°é »åº¦ã‚’ä¸‹ã’ã‚‹ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å„ªå…ˆï¼‰
            if batch_id % 5 == 0:  # 5å›ã«1å›ã®ã¿ãƒ­ã‚°
                logger.info(
                    f"âš¡ Fast batch #{batch_id}: {processed_count} processed, {saved_count} saved in {duration:.3f}s"
                )

        except Exception as e:
            logger.error(f"Error in fast ticker batch: {e}")

    async def _process_ticker_batch(self, tickers: list):
        """ãƒ†ã‚£ãƒƒã‚«ãƒ¼ãƒãƒƒãƒã‚’å‡¦ç†"""
        try:
            start_time = time.time()
            batch_timestamp = time.time()
            processed_count = 0
            saved_count = 0

            # QuestDBä¸€æ‹¬æ›¸ãè¾¼ã¿ç”¨ã®ãƒªã‚¹ãƒˆ
            tick_data_list = []

            for ticker_data in tickers:
                if not isinstance(ticker_data, dict):
                    continue

                symbol = ticker_data.get("symbol", "")
                price = ticker_data.get("lastPrice")
                volume = ticker_data.get("volume24", "0")

                if not symbol or not price:
                    continue

                try:
                    price_f = float(price)
                    volume_f = float(volume)

                    # TickDataä½œæˆï¼ˆtimestampã¯æ•°å€¤å‹ï¼‰
                    tick = TickData(
                        symbol=symbol,
                        price=price_f,
                        timestamp=int(datetime.now().timestamp() * 1_000_000_000),  # ãƒŠãƒç§’å˜ä½
                        volume=volume_f,
                    )

                    # ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã«è¿½åŠ 
                    self.data_manager.add_tick(tick)

                    # QuestDBä¿å­˜ç”¨ãƒªã‚¹ãƒˆã«è¿½åŠ 
                    tick_data_list.append(tick)
                    processed_count += 1

                except (ValueError, TypeError):
                    continue

            # QuestDBä¸€æ‹¬æ›¸ãè¾¼ã¿
            if tick_data_list:
                saved_count = await self._save_to_questdb_batch(
                    tick_data_list, batch_timestamp
                )

            # çµ±è¨ˆæ›´æ–°
            self.stats["ticks_processed"] += processed_count
            self.stats["ticks_saved"] += saved_count

            duration = time.time() - start_time
            logger.info(
                f"âœ… Batch processed: {processed_count} ticks processed, {saved_count} saved to QuestDB in {duration:.3f}s"
            )

        except Exception as e:
            logger.error(f"Error processing ticker batch: {e}")

    async def _save_to_questdb_batch(
        self, tick_data_list: list, batch_timestamp: float
    ) -> int:
        """QuestDBã«ãƒãƒƒãƒã§ä¿å­˜"""
        try:
            # ILPãƒ©ã‚¤ãƒ³å½¢å¼ã§ä¸€æ‹¬æ›¸ãè¾¼ã¿
            ilp_lines = []
            batch_ts_ns = int(batch_timestamp * 1_000_000_000)

            for tick in tick_data_list:
                # MEXCã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãŒãªã„å ´åˆã¯ãƒãƒƒãƒã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä½¿ç”¨
                timestamp_ns = batch_ts_ns

                # ILPå½¢å¼ãƒ©ã‚¤ãƒ³ç”Ÿæˆ
                line = f"tick_data,symbol={tick.symbol} price={tick.price},volume={tick.volume} {timestamp_ns}"
                ilp_lines.append(line)

            # QuestDBã«é€ä¿¡
            if ilp_lines:
                saved_count = self.questdb_client.save_ilp_lines(ilp_lines)
                logger.debug(f"ğŸ’¾ QuestDB: {saved_count} records saved")
                return saved_count

            return 0

        except Exception as e:
            logger.error(f"Error saving to QuestDB: {e}")
            return 0

    async def _save_to_questdb_fast(self, tickers: list, batch_timestamp: float) -> int:
        """é«˜é€ŸQuestDBä¿å­˜"""
        try:
            ilp_lines = []
            batch_ts_ns = int(batch_timestamp * 1_000_000_000)
            
            for ticker_data in tickers:
                if not isinstance(ticker_data, dict):
                    continue
                    
                symbol = ticker_data.get("symbol", "")
                price = ticker_data.get("lastPrice")
                
                if symbol and price:
                    try:
                        price_f = float(price)
                        volume_f = float(ticker_data.get("volume24", "0"))
                        
                        line = f"tick_data,symbol={symbol} price={price_f},volume={volume_f} {batch_ts_ns}"
                        ilp_lines.append(line)
                    except (ValueError, TypeError):
                        continue
            
            if ilp_lines:
                saved_count = self.questdb_client.save_ilp_lines(ilp_lines)
                return saved_count
                
            return 0
        except Exception as e:
            logger.error(f"Error in fast QuestDB save: {e}")
            return 0

    async def _update_data_manager_fast(self, tickers: list) -> int:
        """é«˜é€Ÿdata_manageræ›´æ–°"""
        try:
            processed_count = 0
            
            for ticker_data in tickers:
                if not isinstance(ticker_data, dict):
                    continue
                    
                symbol = ticker_data.get("symbol", "")
                price = ticker_data.get("lastPrice")
                
                if symbol and price:
                    try:
                        price_f = float(price)
                        volume_f = float(ticker_data.get("volume24", "0"))
                        
                        tick = TickData(
                            symbol=symbol,
                            price=price_f,
                            timestamp=int(datetime.now().timestamp() * 1_000_000_000),
                            volume=volume_f,
                        )
                        
                        self.data_manager.add_tick(tick)
                        processed_count += 1
                    except (ValueError, TypeError):
                        continue
                        
            return processed_count
        except Exception as e:
            logger.error(f"Error in fast data manager update: {e}")
            return 0

    async def run(self):
        """ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—å®Ÿè¡Œ"""
        logger.info("ğŸš€ MEXC Data Collectoré–‹å§‹...")

        try:
            # åˆæœŸåŒ–
            await self.initialize()

            # ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¨­å®š
            self._setup_signal_handlers()

            self.running = True
            logger.info(
                "âœ… MEXC Data Collectorç¨¼åƒä¸­ã€‚åœæ­¢ã¯ Ctrl+C ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚"
            )

            # çµ±è¨ˆè¡¨ç¤ºã‚¿ã‚¤ãƒãƒ¼é–‹å§‹
            asyncio.create_task(self._stats_timer())

            # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ï¼ˆåŠ¹ç‡çš„ãªå¾…æ©Ÿï¼‰ - ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ã‚¤ãƒ™ãƒ³ãƒˆã‚’å¾…æ©Ÿ
            await self.shutdown_event.wait()

        except Exception as e:
            logger.error(f"Critical error: {e}")
        finally:
            await self.shutdown()

    async def _stats_timer(self):
        """çµ±è¨ˆè¡¨ç¤ºã‚¿ã‚¤ãƒãƒ¼"""
        while self.running:
            try:
                await asyncio.sleep(30)  # 30ç§’é–“éš”
                if self.running:
                    self._show_stats()
            except Exception as e:
                logger.error(f"Error in stats timer: {e}")

    def _show_stats(self):
        """çµ±è¨ˆæƒ…å ±è¡¨ç¤º"""
        try:
            uptime = (datetime.now() - self.stats["start_time"]).total_seconds()

            logger.info("ğŸ“Š === MEXC Data Collector Statistics ===")
            logger.info(f"â±ï¸  ç¨¼åƒæ™‚é–“: {uptime:.1f}ç§’ ({uptime/60:.1f}åˆ†)")
            logger.info(f"ğŸ“¨ å—ä¿¡ãƒãƒƒãƒæ•°: {self.stats['batches_received']}")
            logger.info(f"ğŸ“ˆ å‡¦ç†ãƒ†ã‚£ãƒƒã‚¯æ•°: {self.stats['ticks_processed']}")
            logger.info(f"ğŸ’¾ QuestDBä¿å­˜æ•°: {self.stats['ticks_saved']}")

            # å‡¦ç†ãƒ¬ãƒ¼ãƒˆ
            if uptime > 0:
                batch_rate = self.stats["batches_received"] / uptime
                tick_rate = self.stats["ticks_processed"] / uptime
                logger.info(
                    f"ğŸ“Š å‡¦ç†ãƒ¬ãƒ¼ãƒˆ: {batch_rate:.2f} batches/s, {tick_rate:.2f} ticks/s"
                )

            logger.info("=" * 50)

        except Exception as e:
            logger.error(f"Error showing stats: {e}")

    def _setup_signal_handlers(self):
        """ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼è¨­å®š"""

        def signal_handler(signum, frame):
            logger.info(f"Received signal {signum}, initiating shutdown...")
            self.running = False
            # ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ã‚¤ãƒ™ãƒ³ãƒˆã‚’ã‚»ãƒƒãƒˆï¼ˆéåŒæœŸãªã®ã§loopçµŒç”±ï¼‰
            asyncio.create_task(self._set_shutdown_event())

        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)

    async def _set_shutdown_event(self):
        """ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³ã‚¤ãƒ™ãƒ³ãƒˆã‚’ã‚»ãƒƒãƒˆ"""
        self.shutdown_event.set()

    async def shutdown(self):
        """ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³å‡¦ç†"""
        logger.info("Shutting down MEXC Data Collector...")

        self.running = False

        try:
            # æœ€çµ‚çµ±è¨ˆè¡¨ç¤º
            self._show_stats()

            # å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³
            if self.mexc_client:
                logger.info("Shutting down MEXC client...")
                await self.mexc_client.stop()

            if self.questdb_client:
                logger.info("Shutting down QuestDB client...")
                self.questdb_client.shutdown()

            if self.data_manager:
                logger.info("Shutting down data manager...")
                self.data_manager.shutdown()

            logger.info("MEXC Data Collector shutdown completed")

        except Exception as e:
            logger.error(f"Error during shutdown: {e}")

    def get_status(self) -> Dict[str, Any]:
        """ç¾åœ¨ã®çŠ¶æ…‹ã‚’å–å¾—"""
        try:
            uptime = (datetime.now() - self.stats["start_time"]).total_seconds()

            return {
                "running": self.running,
                "uptime_hours": uptime / 3600,
                "stats": self.stats,
                "data_manager": (
                    self.data_manager.get_stats() if self.data_manager else {}
                ),
                "questdb": (
                    self.questdb_client.get_stats() if self.questdb_client else {}
                ),
            }
        except Exception as e:
            logger.error(f"Error getting status: {e}")
            return {"error": str(e)}


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import sys

    # ãƒ˜ãƒ«ãƒ—è¡¨ç¤º
    if "--help" in sys.argv or "-h" in sys.argv:
        print("ğŸš€ MEXC Data Collector - MEXCã‹ã‚‰ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’QuestDBã«è¨˜éŒ²")
        print("")
        print("Usage:")
        print("  python main.py                    ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹")
        print("  python main.py --help             ã“ã®ãƒ˜ãƒ«ãƒ—ã‚’è¡¨ç¤ºï¼ˆ-hï¼‰")
        return

    try:
        # MEXC Data Collector ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        app = MEXCDataCollector()

        # å®Ÿè¡Œ
        await app.run()

    except KeyboardInterrupt:
        print("Interrupted by user")
    except Exception as e:
        print(f"Fatal error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    # ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã§å®Ÿè¡Œ
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("Application interrupted")
    except Exception as e:
        print(f"Application failed: {e}")
        sys.exit(1)
